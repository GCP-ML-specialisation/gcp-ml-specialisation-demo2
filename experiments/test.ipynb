{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import (\n",
    "        RandomizedSearchCV,\n",
    "        train_test_split,\n",
    "    )\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "\n",
    "def feature_engineering(df_train: pd.DataFrame, df_test: pd.DataFrame):\n",
    "    # Handle categorical to integer transformation for 'Gender'\n",
    "    gender_mapping = {\"F\": 0, \"M\": 1}\n",
    "    df_train[\"Gender\"] = df_train[\"Gender\"].map(gender_mapping)\n",
    "    df_test[\"Gender\"] = df_test[\"Gender\"].map(gender_mapping)\n",
    "\n",
    "    # Columns to encode\n",
    "    cols = [\"Age\", \"City_Category\", \"Stay_In_Current_City_Years\"]\n",
    "\n",
    "    # Combine train and test for consistent encoding\n",
    "    combined_df = pd.concat([df_train[cols], df_test[cols]], axis=0)\n",
    "\n",
    "    # Initialize the LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Apply LabelEncoder to each column and transform back to DataFrame\n",
    "    for col in cols:\n",
    "        combined_df[col] = le.fit_transform(combined_df[col])\n",
    "\n",
    "    # Split the combined data back into train and test sets\n",
    "    df_train[cols] = combined_df.iloc[: len(df_train), :]\n",
    "    df_test[cols] = combined_df.iloc[len(df_train) :, :]\n",
    "\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "    df_train[\"Purchase\"] = np.log1p(df_train[\"Purchase\"])\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def basic_preprocessing(df_train: pd.DataFrame, df_test: pd.DataFrame):\n",
    "    df_train[\"Stay_In_Current_City_Years\"] = df_train[\n",
    "        \"Stay_In_Current_City_Years\"\n",
    "    ].str.replace(\"+\", \"\")\n",
    "    df_train[\"Stay_In_Current_City_Years\"] = df_train[\n",
    "        \"Stay_In_Current_City_Years\"\n",
    "    ].astype(int)\n",
    "\n",
    "    df_test[\"Stay_In_Current_City_Years\"] = df_test[\n",
    "        \"Stay_In_Current_City_Years\"\n",
    "    ].str.replace(\"+\", \"\")\n",
    "    df_test[\"Stay_In_Current_City_Years\"] = df_test[\n",
    "        \"Stay_In_Current_City_Years\"\n",
    "    ].astype(int)\n",
    "\n",
    "    ## Dropping User_id and Product_ID\n",
    "    df_train = df_train.drop(\"User_ID\", axis=1)\n",
    "    df_test = df_test.drop(\"User_ID\", axis=1)\n",
    "    df_train = df_train.drop(\"Product_ID\", axis=1)\n",
    "    df_test = df_test.drop(\"Product_ID\", axis=1)\n",
    "\n",
    "    df_train = df_train.drop(\"Product_Category_3\", axis=1)\n",
    "    df_test = df_test.drop(\"Product_Category_3\", axis=1)\n",
    "\n",
    "    ## Imputing missing values with mode\n",
    "    df_train[\"Product_Category_2\"].mode()[0]\n",
    "    df_train[\"Product_Category_2\"] = df_train[\"Product_Category_2\"].fillna(\n",
    "        df_train[\"Product_Category_2\"].mode()[0]\n",
    "    )\n",
    "    df_train.isnull().sum()\n",
    "\n",
    "    df_test[\"Product_Category_2\"].mode()[0]\n",
    "    df_test[\"Product_Category_2\"] = df_test[\"Product_Category_2\"].fillna(\n",
    "        df_test[\"Product_Category_2\"].mode()[0]\n",
    "    )\n",
    "    df_test.isnull().sum()\n",
    "\n",
    "    return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'C:\\Users\\CAMNG3\\Downloads\\train.csv')\n",
    "df_test = pd.read_csv(r'C:\\Users\\CAMNG3\\Downloads\\test.csv')\n",
    "\n",
    "df_train, df_test = basic_preprocessing(df_train, df_test)\n",
    "df_train, df_test = feature_engineering(df_train, df_test)\n",
    "\n",
    "df_train.to_csv(r\".\\data\\pre_processed_train.csv\", index=False)\n",
    "df_test.to_csv(r\".\\data\\pre_processed_test.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_train.drop('Purchase',axis=1)\n",
    "y=df_train['Purchase']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Test set MAE 0.2859335382173821\n",
      "XGB Test set MSE 0.15213890327265409\n",
      "XGB Test R2_Score 0.7206602250216348\n",
      "XGB Test RMSE of XGBoost Model is  0.3900498728017407\n",
      "----------------------------------\n",
      "Random Forest Test set MAE 0.28264333427329164\n",
      "Random Forest Test set MSE 0.1463590336157364\n",
      "Random Forest Test R2_Score 0.7312725500393469\n",
      "Random Forest Test RMSE of Regressor Model is  0.3825689919684244\n"
     ]
    }
   ],
   "source": [
    "xgb_reg = xgb.XGBRegressor(learning_rate=0.5, max_depth=15, seed=0)\n",
    "\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "xgb_y_pred = xgb_reg.predict(X_train)\n",
    "print('Training set MAE',mean_absolute_error(y_train, xgb_y_pred))\n",
    "print('Training set MSE',mean_squared_error(y_train, xgb_y_pred))\n",
    "print('Training R2_Score',r2_score(y_train, xgb_y_pred))\n",
    "print(\"Training RMSE of XGBoost Model is \",sqrt(mean_squared_error(y_train, xgb_y_pred)))\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "xgb_y_pred = xgb_reg.predict(X_test)\n",
    "print('Test set MAE',mean_absolute_error(y_test, xgb_y_pred))\n",
    "print('Test set MSE',mean_squared_error(y_test, xgb_y_pred))\n",
    "print('Test R2_Score',r2_score(y_test, xgb_y_pred))\n",
    "from math import sqrt\n",
    "print(\"Test RMSE of XGBoost Model is \",sqrt(mean_squared_error(y_test, xgb_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set MAE 0.23634514883449112\n",
      "Training set MSE 0.10665119059453569\n",
      "Training R2_Score 0.8051570567953704\n",
      "Training RMSE of Regressor Model is  0.32657493871167714\n",
      "----------------------------------\n",
      "Test set MAE 0.28264333427329164\n",
      "Test set MSE 0.1463590336157364\n",
      "Test R2_Score 0.7312725500393469\n",
      "Test RMSE of Regressor Model is  0.3825689919684244\n"
     ]
    }
   ],
   "source": [
    "# Fitting Random Forest Regression to the dataset\n",
    "regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    " \n",
    "# Fit the regressor with x and y data\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "regr_y_pred = regressor.predict(X_train)\n",
    "\n",
    "print('Training set MAE',mean_absolute_error(y_train, regr_y_pred))\n",
    "print('Training set MSE',mean_squared_error(y_train, regr_y_pred))\n",
    "print('Training R2_Score',r2_score(y_train, regr_y_pred))\n",
    "print(\"Training RMSE of Regressor Model is \",sqrt(mean_squared_error(y_train, regr_y_pred)))\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "regr_y_pred = regressor.predict(X_test)\n",
    "print('Test set MAE',mean_absolute_error(y_test, regr_y_pred))\n",
    "print('Test set MSE',mean_squared_error(y_test, regr_y_pred))\n",
    "print('Test R2_Score',r2_score(y_test, regr_y_pred))\n",
    "print(\"Test RMSE of Regressor Model is \",sqrt(mean_squared_error(y_test, regr_y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set MAE 0.2814727951442279\n",
      "Test set MSE 0.14050631475177378\n",
      "Test R2_Score 0.7420186323056361\n",
      "Test RMSE of Regressor Model is  0.3748417195987845\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "\n",
    "param_dist = {\n",
    "    \"max_depth\": randint(5, 15),  # Maximum depth of the tree\n",
    "    \"n_estimators\": randint(9, 13),\n",
    "    \"min_samples_leaf\": randint(1, 3),\n",
    "}\n",
    "\n",
    "param_comb = 5\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    regressor,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=param_comb,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=10,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "regressor_best = random_search.best_estimator_\n",
    "\n",
    "regr_y_pred = regressor_best.predict(X_test)\n",
    "print('Test set MAE',mean_absolute_error(y_test, regr_y_pred))\n",
    "print('Test set MSE',mean_squared_error(y_test, regr_y_pred))\n",
    "print('Test R2_Score',r2_score(y_test, regr_y_pred))\n",
    "print(\"Test RMSE of Regressor Model is \",sqrt(mean_squared_error(y_test, regr_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform \n",
    "\n",
    "PROJECT_NUMBER='121050757542'\n",
    "ENDPOINT_ID='9119259280820666368'\n",
    "\n",
    "endpoint_name = f\"projects/{PROJECT_NUMBER}/locations/us-central1/endpoints/{ENDPOINT_ID}\"\n",
    "endpoint = aiplatform.Endpoint(endpoint_name=endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# endpoint.predict(instances=xgb.DMatrix([[1,2,3,4,5,6,87,9]]).get_data().A.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
