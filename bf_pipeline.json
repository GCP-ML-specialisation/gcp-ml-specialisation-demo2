{
  "components": {
    "comp-basic-preprocessing": {
      "executorLabel": "exec-basic-preprocessing",
      "inputDefinitions": {
        "parameters": {
          "bucket_URI": {
            "parameterType": "STRING"
          },
          "folder": {
            "parameterType": "STRING"
          },
          "test": {
            "parameterType": "STRING"
          },
          "train": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "dataset_test": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "dataset_train": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-data-transformation": {
      "executorLabel": "exec-data-transformation",
      "inputDefinitions": {
        "artifacts": {
          "df_test": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "df_train": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "dataset_test": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "dataset_train": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-deploy-rf-model": {
      "executorLabel": "exec-deploy-rf-model",
      "inputDefinitions": {
        "artifacts": {
          "model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            },
            "description": "The model to deploy."
          }
        },
        "parameters": {
          "project_id": {
            "description": "The project ID of the Vertex AI Endpoint.",
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "vertex_endpoint": {
            "artifactType": {
              "schemaTitle": "system.Artifact",
              "schemaVersion": "0.0.1"
            },
            "description": "The deployed Vertex AI Endpoint."
          },
          "vertex_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            },
            "description": "The deployed Vertex AI Model."
          }
        }
      }
    },
    "comp-model-evaluation": {
      "executorLabel": "exec-model-evaluation",
      "inputDefinitions": {
        "artifacts": {
          "test_set": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "training_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "kpi": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-train-validation-test-split": {
      "executorLabel": "exec-train-validation-test-split",
      "inputDefinitions": {
        "artifacts": {
          "df_train": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "validation_size": {
            "defaultValue": 0.2,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "dataset_train": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "dataset_valid": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-training-hyperp-tuning": {
      "executorLabel": "exec-training-hyperp-tuning",
      "inputDefinitions": {
        "artifacts": {
          "df_train": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "trained_model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    }
  },
  "defaultPipelineRoot": "gs://pa_poc_mlspec_2_pipeline//pipeline_root",
  "deploymentSpec": {
    "executors": {
      "exec-basic-preprocessing": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "basic_preprocessing"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'gcsfs' 'scikit-learn==1.3.0' 'numpy==1.23.5' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef basic_preprocessing(\n    bucket_URI: str,\n    folder: str,\n    train: str,\n    test: str,\n    dataset_train: Output[Dataset],\n    dataset_test: Output[Dataset],\n):\n\n    import pandas as pd\n\n    df_train_uri = \"\".join([bucket_URI, folder, train])\n    df_test_uri = \"\".join([bucket_URI, folder, test])\n\n    df_train = pd.read_csv(df_train_uri)\n    df_test = pd.read_csv(df_test_uri)\n\n    df_train[\"Stay_In_Current_City_Years\"] = df_train[\n        \"Stay_In_Current_City_Years\"\n    ].str.replace(\"+\", \"\")\n    df_train[\"Stay_In_Current_City_Years\"] = df_train[\n        \"Stay_In_Current_City_Years\"\n    ].astype(int)\n\n    df_test[\"Stay_In_Current_City_Years\"] = df_test[\n        \"Stay_In_Current_City_Years\"\n    ].str.replace(\"+\", \"\")\n    df_test[\"Stay_In_Current_City_Years\"] = df_test[\n        \"Stay_In_Current_City_Years\"\n    ].astype(int)\n\n    ## Dropping User_id and Product_ID\n    df_train = df_train.drop(\"User_ID\", axis=1)\n    df_test = df_test.drop(\"User_ID\", axis=1)\n    df_train = df_train.drop(\"Product_ID\", axis=1)\n    df_test = df_test.drop(\"Product_ID\", axis=1)\n\n    df_train = df_train.drop(\"Product_Category_3\", axis=1)\n    df_test = df_test.drop(\"Product_Category_3\", axis=1)\n\n    ## Imputing missing values with mode\n    df_train[\"Product_Category_2\"].mode()[0]\n    df_train[\"Product_Category_2\"] = df_train[\"Product_Category_2\"].fillna(\n        df_train[\"Product_Category_2\"].mode()[0]\n    )\n\n    df_test[\"Product_Category_2\"].mode()[0]\n    df_test[\"Product_Category_2\"] = df_test[\"Product_Category_2\"].fillna(\n        df_test[\"Product_Category_2\"].mode()[0]\n    )\n\n    df_train.to_csv(dataset_train.path + \".csv\", index=False)\n    df_test.to_csv(dataset_test.path + \".csv\", index=False)\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-data-transformation": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "data_transformation"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'gcsfs' 'scikit-learn==1.3.0' 'numpy==1.23.5' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef data_transformation(\n    df_train: Input[Dataset],\n    df_test: Input[Dataset],\n    dataset_train: Output[Dataset],\n    dataset_test: Output[Dataset],\n):\n\n    import pandas as pd\n    from sklearn.preprocessing import LabelEncoder\n    import numpy as np\n\n    df_train = pd.read_csv(df_train.path + \".csv\")\n    df_test = pd.read_csv(df_test.path + \".csv\")\n\n    # Handle categorical to integer transformation for 'Gender'\n    gender_mapping = {\"F\": 0, \"M\": 1}\n    df_train[\"Gender\"] = df_train[\"Gender\"].map(gender_mapping)\n    df_test[\"Gender\"] = df_test[\"Gender\"].map(gender_mapping)\n\n    # Columns to encode\n    cols = [\"Age\", \"City_Category\", \"Stay_In_Current_City_Years\"]\n\n    # Combine train and test for consistent encoding\n    combined_df = pd.concat([df_train[cols], df_test[cols]], axis=0)\n\n    # Initialize the LabelEncoder\n    le = LabelEncoder()\n\n    # Apply LabelEncoder to each column and transform back to DataFrame\n    for col in cols:\n        combined_df[col] = le.fit_transform(combined_df[col])\n\n    # Split the combined data back into train and test sets\n    df_train[cols] = combined_df.iloc[: len(df_train), :]\n    df_test[cols] = combined_df.iloc[len(df_train) :, :]\n\n    df_train[\"Purchase\"] = np.log1p(df_train[\"Purchase\"])\n\n    df_train.to_csv(dataset_train.path + \".csv\", index=False)\n    df_test.to_csv(dataset_test.path + \".csv\", index=False)\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-deploy-rf-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "deploy_rf_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform==1.25.0' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef deploy_rf_model(\n    model: Input[Model],\n    project_id: str,\n    vertex_endpoint: Output[Artifact],\n    vertex_model: Output[Model],\n):\n    \"\"\"Deploys an XGBoost model to Vertex AI Endpoint.\n\n    Args:\n        model: The model to deploy.\n        project_id: The project ID of the Vertex AI Endpoint.\n\n    Returns:\n        vertex_endpoint: The deployed Vertex AI Endpoint.\n        vertex_model: The deployed Vertex AI Model.\n    \"\"\"\n    from google.cloud import aiplatform\n\n    aiplatform.init(project=project_id)\n\n    deployed_model = aiplatform.Model.upload(\n        display_name=\"bf_model\",\n        artifact_uri=model.uri,\n        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest\",\n    )\n    endpoint = deployed_model.deploy(\n        deployed_model_display_name=\"bf_random_forest_model\",\n        machine_type=\"n1-standard-4\",\n    )\n\n    vertex_endpoint.uri = endpoint.resource_name\n    vertex_model.uri = deployed_model.resource_name\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-model-evaluation": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "model_evaluation"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'numpy==1.23.5' 'gcsfs' 'scikit-learn==1.3.0' 'joblib' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef model_evaluation(\n    test_set: Input[Dataset],\n    training_model: Input[Model],\n    kpi: Output[Metrics],\n):\n    import pandas as pd\n    from math import sqrt\n    import os\n    import joblib\n    import numpy as np\n    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n    data = pd.read_csv(test_set.path + \".csv\")\n    file_name = os.path.join(training_model.path, \"model.joblib\")\n\n    model = joblib.load(file_name)\n\n    X_test = data.drop(\"Purchase\", axis=1)\n    y_test = np.array(data[\"Purchase\"])\n\n    xgb_y_pred = model.predict(X_test)\n\n    mae = mean_absolute_error(y_test, xgb_y_pred)\n    mse = mean_squared_error(y_test, xgb_y_pred)\n    r2 = r2_score(y_test, xgb_y_pred)\n    rmse = sqrt(mean_squared_error(y_test, xgb_y_pred))\n\n    training_model.metadata[\"mean_absolute_error\"] = mae\n    training_model.metadata[\"mean_squared_error\"] = mse\n    training_model.metadata[\"R2_Score\"] = r2\n    training_model.metadata[\"root_mean_absolute_error\"] = rmse\n\n    kpi.log_metric(\"mean_absolute_error\", mae)\n    kpi.log_metric(\"mean_squared_error\", mse)\n    kpi.log_metric(\"R2_Score\", r2)\n    kpi.log_metric(\"root_mean_absolute_error\", rmse)\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-train-validation-test-split": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_validation_test_split"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'gcsfs' 'numpy==1.23.5' 'scikit-learn==1.3.0' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_validation_test_split(\n    df_train: Input[Dataset],\n    dataset_train: Output[Dataset],\n    dataset_valid: Output[Dataset],\n    validation_size: float = 0.2,\n):\n\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n\n    df_train = pd.read_csv(df_train.path + \".csv\")\n\n    df_train, df_valid = train_test_split(\n        df_train, test_size=validation_size, random_state=42\n    )\n\n    df_train.to_csv(dataset_train.path + \".csv\", index=False)\n    df_valid.to_csv(dataset_valid.path + \".csv\", index=False)\n\n"
          ],
          "image": "python:3.10"
        }
      },
      "exec-training-hyperp-tuning": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "training_hyperp_tuning"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'gcsfs' 'numpy==1.23.5' 'scikit-learn==1.3.0' 'joblib' 'scipy' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef training_hyperp_tuning(\n    df_train: Input[Dataset],\n    trained_model: Output[Model],\n):\n\n    import pandas as pd\n    import os\n    import joblib\n    from sklearn.ensemble import RandomForestRegressor\n    from sklearn.model_selection import (\n        RandomizedSearchCV,\n        StratifiedKFold,\n    )\n    from scipy.stats import randint, uniform\n\n    df_train = pd.read_csv(df_train.path + \".csv\")\n\n    x = df_train.drop(\"Purchase\", axis=1)\n    y = df_train[\"Purchase\"]\n\n    regressor = RandomForestRegressor(n_estimators=10, random_state=42, oob_score=True)\n\n    # Define the parameter distributions\n    param_dist = {\n        \"n_estimators\": randint(50, 500),  # Number of trees in the forest\n        \"max_features\": [\n            \"auto\",\n            \"sqrt\",\n            \"log2\",\n        ],  # Number of features to consider at each split\n        \"max_depth\": randint(10, 100),  # Maximum depth of the tree\n        \"min_samples_split\": randint(\n            2, 20\n        ),  # Minimum number of samples required to split a node\n        \"min_samples_leaf\": randint(\n            1, 20\n        ),  # Minimum number of samples required to be at a leaf node\n        \"bootstrap\": [\n            True,\n            False,\n        ],  # Whether bootstrap samples are used when building trees\n        \"min_impurity_decrease\": uniform(\n            0, 0.1\n        ),  # Threshold for early stopping in tree growth\n    }\n\n    param_comb = 20\n\n    random_search = RandomizedSearchCV(\n        regressor,\n        param_distributions=param_dist,\n        n_iter=param_comb,\n        scoring=\"neg_root_mean_squared_error\",\n        cv=5,\n        verbose=4,\n        random_state=42,\n    )\n\n    random_search.fit(x, y)\n    regressor_best = random_search.best_estimator_\n\n    trained_model.metadata[\"framework\"] = \"RandomForestRegressor\"\n    os.makedirs(trained_model.path, exist_ok=True)\n    joblib.dump(regressor_best, os.path.join(trained_model.path, \"model.joblib\"))\n\n"
          ],
          "image": "python:3.10"
        }
      }
    }
  },
  "pipelineInfo": {
    "description": "A simple intro pipeline",
    "name": "intro-pipeline-unique"
  },
  "root": {
    "dag": {
      "outputs": {
        "artifacts": {
          "model-evaluation-kpi": {
            "artifactSelectors": [
              {
                "outputArtifactKey": "kpi",
                "producerSubtask": "model-evaluation"
              }
            ]
          }
        }
      },
      "tasks": {
        "basic-preprocessing": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-basic-preprocessing"
          },
          "inputs": {
            "parameters": {
              "bucket_URI": {
                "componentInputParameter": "BUCKET_URI"
              },
              "folder": {
                "componentInputParameter": "raw_folder"
              },
              "test": {
                "componentInputParameter": "test_name"
              },
              "train": {
                "componentInputParameter": "train_name"
              }
            }
          },
          "taskInfo": {
            "name": "basic-preprocessing"
          }
        },
        "data-transformation": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-data-transformation"
          },
          "dependentTasks": [
            "basic-preprocessing"
          ],
          "inputs": {
            "artifacts": {
              "df_test": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "dataset_test",
                  "producerTask": "basic-preprocessing"
                }
              },
              "df_train": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "dataset_train",
                  "producerTask": "basic-preprocessing"
                }
              }
            }
          },
          "taskInfo": {
            "name": "data-transformation"
          }
        },
        "deploy-rf-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-deploy-rf-model"
          },
          "dependentTasks": [
            "training-hyperp-tuning"
          ],
          "inputs": {
            "artifacts": {
              "model": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "trained_model",
                  "producerTask": "training-hyperp-tuning"
                }
              }
            },
            "parameters": {
              "project_id": {
                "runtimeValue": {
                  "constant": "pa-poc-mlspec-2"
                }
              }
            }
          },
          "taskInfo": {
            "name": "deploy-rf-model"
          }
        },
        "model-evaluation": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-model-evaluation"
          },
          "dependentTasks": [
            "train-validation-test-split",
            "training-hyperp-tuning"
          ],
          "inputs": {
            "artifacts": {
              "test_set": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "dataset_valid",
                  "producerTask": "train-validation-test-split"
                }
              },
              "training_model": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "trained_model",
                  "producerTask": "training-hyperp-tuning"
                }
              }
            }
          },
          "taskInfo": {
            "name": "model-evaluation"
          }
        },
        "train-validation-test-split": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-validation-test-split"
          },
          "dependentTasks": [
            "data-transformation"
          ],
          "inputs": {
            "artifacts": {
              "df_train": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "dataset_train",
                  "producerTask": "data-transformation"
                }
              }
            }
          },
          "taskInfo": {
            "name": "train-validation-test-split"
          }
        },
        "training-hyperp-tuning": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-training-hyperp-tuning"
          },
          "dependentTasks": [
            "train-validation-test-split"
          ],
          "inputs": {
            "artifacts": {
              "df_train": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "dataset_train",
                  "producerTask": "train-validation-test-split"
                }
              }
            }
          },
          "taskInfo": {
            "name": "training-hyperp-tuning"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "BUCKET_URI": {
          "defaultValue": "gs://pa_poc_mlspec_2_pipeline/",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "raw_folder": {
          "defaultValue": "raw_data/",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "test_name": {
          "defaultValue": "test.csv",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "train_name": {
          "defaultValue": "train.csv",
          "isOptional": true,
          "parameterType": "STRING"
        }
      }
    },
    "outputDefinitions": {
      "artifacts": {
        "model-evaluation-kpi": {
          "artifactType": {
            "schemaTitle": "system.Metrics",
            "schemaVersion": "0.0.1"
          }
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.7.0"
}